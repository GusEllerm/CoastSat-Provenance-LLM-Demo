```python exec
# This code makes the micropublication aware of its interface data.
import os
import multiprocessing as _mp

try:
    _mp.set_start_method("spawn")
except RuntimeError:
    pass

from sklearn.metrics import r2_score, mean_squared_error
from sklearn.linear_model import LinearRegression
from typing import Optional, List, Dict, Any
from plotly.subplots import make_subplots
from shapely.geometry import LineString
from rocrate.rocrate import ROCrate, ContextEntity
from dataclasses import dataclass
from pandas import json_normalize
from types import SimpleNamespace
from datetime import datetime
from pathlib import Path
from scipy import stats
from math import sqrt

os.environ.setdefault("PROJ_NETWORK", "OFF")
os.environ.setdefault("PROJ_CACHE_PATH", str((Path.cwd() / ".proj_cache").resolve()))
Path(os.environ["PROJ_CACHE_PATH"]).mkdir(parents=True, exist_ok=True)

import plotly.graph_objects as go
import matplotlib.pyplot as plt
import plotly.express as px
import geopandas as gpd
import contextily as cx
import pandas as pd
import numpy as np
import statistics
import requests
import folium
import json
import sys
import re

# For this example, we'll use a fixed site_id
site_id = "nzd0001"
```

```python exec
# Load the interface.crate and batch_processes.crate manifest files (if available)
# For deployment, we primarily rely on cached data files
interface_crate_path = Path.cwd() / "interface.crate" 
batch_processes_crate_path = interface_crate_path / "batch_processes"

# Check for cached data files
cached_shoreline_path = Path.cwd() / "cached_shoreline.geojson"
cached_primary_result_path = Path.cwd() / "cached_primary_result.geojson"

try:
    if interface_crate_path.exists() and batch_processes_crate_path.exists():
        interface_crate = ROCrate(interface_crate_path)
        batch_processes_crate = ROCrate(batch_processes_crate_path)
    else:
        print("Local crate files not found - using cached data files only")
        interface_crate = None
        batch_processes_crate = None
except Exception as e:
    interface_crate = None
    batch_processes_crate = None
    print(f"Error loading interface and batch processes crates (will use cached data): {e}")
```

```python exec
# Function to extract commit date from GitHub API
def get_commit_date(github_commit_url):
    """Extract commit date from a GitHub commit URL"""
    if not github_commit_url:
        return None
    
    # Extract repo and commit hash from URL
    import re
    match = re.match(r"https://github\.com/(.+)/(.+)/commit/([a-f0-9]+)", github_commit_url)
    if not match:
        return None
    
    owner, repo, commit_hash = match.groups()
    
    try:
        # Make API request to get commit info
        import requests
        api_url = f"https://api.github.com/repos/{owner}/{repo}/commits/{commit_hash}"
        response = requests.get(api_url)
        if response.status_code == 200:
            commit_data = response.json()
            commit_date = commit_data['commit']['committer']['date']
            # Convert to readable format
            from datetime import datetime
            dt = datetime.fromisoformat(commit_date.replace('Z', '+00:00'))
            return dt.strftime('%B %d, %Y')
        else:
            return None
    except Exception as e:
        print(f"Error fetching commit date: {e}")
        return None

# Extract version information
coastsat_version = interface_crate.mainEntity.get("version") if interface_crate else None
coastsat_commit_date = get_commit_date(coastsat_version)
```

```python exec
import importlib.util
import os

_possible_paths = [
    Path("extract_steps_mini.py"),
    Path("./extract_steps_mini.py"),
    Path("examples/CoastSat-example/extract_steps_mini.py"),
]
_extract_steps_path = next((p for p in _possible_paths if p.exists()), None)
if _extract_steps_path is None:
    raise ImportError("Could not find extract_steps_mini.py in known locations")
if _extract_steps_path.exists():
    spec = importlib.util.spec_from_file_location("extract_steps_mini", str(_extract_steps_path))
    extract_steps_mini = importlib.util.module_from_spec(spec)
    sys.modules["extract_steps_mini"] = extract_steps_mini
    spec.loader.exec_module(extract_steps_mini)
    extract_step_dicts = extract_steps_mini.extract_step_dicts
else:
    raise ImportError("Could not find extract_steps_mini.py to import extract_step_dicts")

step_dicts = extract_step_dicts('interface.crate')
for step_entry in step_dicts:
    if step_entry.get("tables", {}).get("notebook_cells"):
        step_entry["jupyter"] = True
    else:
        step_entry["jupyter"] = False

all_steps = step_dicts
for index, step_entry in enumerate(all_steps, start=1):
    step_entry["_sequence"] = index

def _summary_text(stats: dict | None, key: str) -> str:
    if not stats:
        return ""
    return stats.get(key, "")

def _param_brief(entry: dict, site_filter: str | None = None) -> dict:
    sample_links = entry.get("prompt_example_links") or entry.get("linked_examples") or []
    if site_filter:
        filtered_links = [
            link for link in sample_links if isinstance(link, str) and site_filter in link
        ]
        if filtered_links:
            sample_links = filtered_links
    sample_links = sample_links[:1]
    return {
        "parameter": entry.get("parameter"),
        "name": entry.get("name"),
        "format": entry.get("format"),
        "description": entry.get("description"),
        "source_link": entry.get("prompt_link"),
        "sample_example": sample_links,
        "total_files": entry.get("total_files"),
        "transient_note": entry.get("transient_note"),
    }

workflow_steps_summary = []
workflow_outcomes = []
for step_summary in all_steps:
    stats = step_summary.get("stats") or {}
    inputs = step_summary.get("inputs_overview") or []
    outputs = step_summary.get("outputs_overview") or []
    step_identity = {
        "name": step_summary.get("name"),
        "position": step_summary.get("position"),
        "language": step_summary.get("language"),
        "code_repository": step_summary.get("code_repository"),
    }
    if step_identity.get("code_repository") and step_identity.get("name"):
        step_identity["code_repository_markdown"] = f"[{step_identity['name']}]({step_identity['code_repository']})"
    else:
        step_identity["code_repository_markdown"] = None

    ordered_outputs = []
    for output in outputs:
        brief = _param_brief(output, site_id)
        ordered_outputs.append(brief)
        sample_link = brief["sample_example"][0] if brief["sample_example"] else None
        workflow_outcomes.append(
            {
                "step_name": step_summary.get("name"),
                "parameter": output.get("parameter"),
                "name": output.get("name"),
                "format": output.get("format"),
                "description": output.get("description"),
                "sample_link": sample_link,
                "total_files": output.get("total_files"),
                "transient_note": output.get("transient_note"),
            }
        )

    workflow_steps_summary.append(
        {
            "name": step_summary.get("name"),
            "position": step_summary.get("position"),
            "code_repository_markdown": step_identity.get("code_repository_markdown"),
            "language": step_summary.get("language"),
            "inputs_summary": _summary_text(stats, "input_summary"),
            "outputs_summary": _summary_text(stats, "output_summary"),
            "inputs": [_param_brief(entry, site_id) for entry in inputs[:3]],
            "outputs": ordered_outputs[:3],
        }
    )

workflow_overview_input = {
    "site": site_id,
    "total_steps": len(all_steps),
    "steps": workflow_steps_summary,
}

workflow_diagram_input = {
    "steps": workflow_steps_summary,
    "step_order": [item.get("name") for item in sorted(workflow_steps_summary, key=lambda entry: entry.get("position", 0))],
}

workflow_outcomes_input = {
    "site": site_id,
    "outcomes": workflow_outcomes,
}

display_steps = all_steps

```

# CoastSat Methodology: Experimental LLM Publication

## Workflow Overview
:::::: template_describe @livepublication/coastsat/workflow/overview-v2 [openai/gpt-5] {{workflow_overview_input}} :::::

### Workflow Diagram
:::::: template_describe @livepublication/coastsat/workflow/diagram-v2 [openai/gpt-5] {{workflow_diagram_input}} :::::

### Primary Outcomes
:::::: template_describe @livepublication/coastsat/workflow/outcomes-v2 [openai/gpt-5] {{workflow_outcomes_input}} :::::

::::: for step in display_steps

```python exec
identity = {
    "name": step.get("name"),
    "position": step.get("position"),
    "language": step.get("language"),
    "code_repository": step.get("code_repository"),
    "step_number": step.get("_sequence"),
}
code_repo_url = identity.get("code_repository")
step_name = identity.get("name")
if code_repo_url and step_name:
    identity["code_repository_markdown"] = f"[{step_name}]({code_repo_url})"
else:
    identity["code_repository_markdown"] = None

link_lists = step.get("link_lists") or {}
stats = step.get("stats") or {}

data_flows = {
    "inputs": {
        "count": stats.get("input_parameter_count"),
        "summary": stats.get("input_summary"),
        "examples": stats.get("input_examples"),
        "links": link_lists.get("inputs"),
    },
    "outputs": {
        "count": stats.get("output_parameter_count"),
        "summary": stats.get("output_summary"),
        "examples": stats.get("output_examples"),
        "links": link_lists.get("outputs"),
    },
}

linked_artefacts = {
    "inputs": {
        "summary": stats.get("linked_input_summary"),
        "examples": stats.get("linked_input_examples"),
        "links": stats.get("linked_input_links"),
        "parameters": stats.get("linked_input_parameter_count"),
        "file_count": stats.get("linked_input_file_count"),
    },
    "outputs": {
        "summary": stats.get("linked_output_summary"),
        "examples": stats.get("linked_output_examples"),
        "links": stats.get("linked_output_links"),
        "parameters": stats.get("linked_output_parameter_count"),
        "file_count": stats.get("linked_output_file_count"),
    },
}

notebook_cells_all = step.get("notebook_cells") or []
notebook_cells_with_content = [cell for cell in notebook_cells_all if cell.get("content")]
max_cells = 10
cells_for_prompt = []
for cell in notebook_cells_with_content[:max_cells]:
    cell_name = cell.get("name") or f"Cell {cell.get('position')}"
    cells_for_prompt.append(
        {
            "name": cell_name,
        "position": cell.get("position"),
            "path": cell.get("path"),
            "uri": cell.get("uri"),
            "content": cell.get("content"),
            "content_truncated": cell.get("content_truncated"),
    }
    )

notebook_context = {
    "summary": step.get("notebook_summary_text"),
    "total_cells": len(notebook_cells_all),
    "cells_included": len(cells_for_prompt),
    "additional_cells": max(0, len(notebook_cells_with_content) - len(cells_for_prompt)),
    "cells": cells_for_prompt,
    "available_cell_names": [cell.get("name") or f"Cell {cell.get('position')}" for cell in notebook_cells_all],
}

context_lines = [line for line in (step.get("prompt_context") or "").splitlines() if line]

def _clean(value):
    if value in (None, "", "â€“"):
        return None
    return value

def _build_param_payload(entry: dict, kind: str) -> dict:
    sample_prompt_links = [
        link
        for link in (entry.get("prompt_example_links") or [])
        if isinstance(link, str) and link and link != entry.get("name")
    ]
    if site_id:
        site_filtered = [link for link in sample_prompt_links if site_id in link]
        if site_filtered:
            sample_prompt_links = site_filtered
    total_files = entry.get("total_files") or 0
    primary_example_links = sample_prompt_links[:1]

    if total_files:
        linked_note = f"{total_files} linked file{'s' if total_files != 1 else ''} referenced in the crate"
        if primary_example_links:
            linked_note += f"; representative example: {primary_example_links[0]}"
        else:
            linked_note += " (no public URLs)."
    else:
        linked_note = "No linked files recorded."

    cell_refs = [ref for ref in (entry.get("cell_refs") or []) if ref]
    cell_refs_text = ", ".join(cell_refs)
    cell_refs_note = (
        f"Notebook cells: {cell_refs_text}" if cell_refs_text else "Notebook cells: not documented."
    )

    return {
        "step": identity,
        "parameter": entry.get("parameter"),
        "name": entry.get("name"),
        "format": _clean(entry.get("format")),
        "description": _clean(entry.get("description")),
        "source_link": entry.get("prompt_link"),
        "linked_examples": primary_example_links,
        "total_linked_files": total_files,
        "linked_files_note": linked_note,
        "transient_note": entry.get("transient_note"),
        "context_lines": context_lines,
        "cell_refs": cell_refs,
        "cell_refs_text": cell_refs_text,
        "cell_refs_note": cell_refs_note,
        "kind": kind,
    }

inputs_prompt_payload = [
    _build_param_payload(entry, "input")
    for entry in (step.get("inputs_overview") or [])
]
outputs_prompt_payload = [
    _build_param_payload(entry, "output")
    for entry in (step.get("outputs_overview") or [])
]

step_title_input = identity
step_objective_input = {
    "identity": identity,
    "data_flows": data_flows,
    "linked_artefacts": linked_artefacts,
    "notebook": {"summary": notebook_context.get("summary")},
    "context_lines": context_lines,
    "inputs": step.get("inputs_overview"),
    "outputs": step.get("outputs_overview"),
}
step_operations_input = {
    "identity": identity,
    "data_flows": data_flows,
    "linked_artefacts": linked_artefacts,
    "notebook": notebook_context,
    "context_lines": context_lines,
    "inputs": step.get("inputs_overview"),
    "outputs": step.get("outputs_overview"),
    }
```

:::::: template_describe @livepublication/coastsat/step/title-v2 [openai/gpt-5] {{step_title_input}} ::::: 

> [!info]+ Step Metadata
> ```python exec
> step["tables"]["metadata"]
> ```

### Objective
:::::: template_describe @livepublication/coastsat/step/objective-v2 [openai/gpt-5] {{step_objective_input}} ::::: 

### Operations
:::::: template_describe @livepublication/coastsat/step/operations-v3 [openai/gpt-5] {{step_operations_input}} ::::: 

### Step Inputs
::::: if inputs_prompt_payload
:::::: for input_payload in inputs_prompt_payload
**{{input_payload["parameter"]}}**

::::::: template_describe @livepublication/coastsat/step/input-v2 [openai/gpt-5] {{input_payload}} ::::::: 

::::::
:::::

### Step Outputs
::::: if outputs_prompt_payload
:::::: for output_payload in outputs_prompt_payload
**{{output_payload["parameter"]}}**

::::::: template_describe @livepublication/coastsat/step/output-v2 [openai/gpt-5] {{output_payload}} ::::::: 

::::::
:::::
:::::
